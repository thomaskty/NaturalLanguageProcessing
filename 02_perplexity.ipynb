{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f50acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_perplexity(logits, target):\n",
    "    \"\"\"\n",
    "    Calculate perplexity from logits and target labels.\n",
    "\n",
    "    Args:\n",
    "    - logits (torch.Tensor): Logits output from the model (batch_size, seq_length, vocab_size).\n",
    "    - target (torch.Tensor): Ground truth labels (batch_size, seq_length).\n",
    "\n",
    "    Returns:\n",
    "    - perplexity (float): The perplexity score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert logits to log probabilities\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Gather the log probabilities for the correct target tokens\n",
    "    # log_probs has shape (batch_size, seq_length, vocab_size)\n",
    "    # target has shape (batch_size, seq_length)\n",
    "    # The gather method will pick the log probabilities of the true target tokens\n",
    "    target_log_probs = log_probs.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Calculate the negative log likelihood\n",
    "    negative_log_likelihood = -target_log_probs\n",
    "\n",
    "    # Calculate the mean negative log likelihood over all tokens\n",
    "    mean_nll = negative_log_likelihood.mean()\n",
    "\n",
    "    # Calculate perplexity as exp(mean negative log likelihood)\n",
    "    perplexity = torch.exp(mean_nll)\n",
    "\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b353810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 11.153843879699707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "# Simulate a batch of logits (batch_size=2, seq_length=4, vocab_size=10)\n",
    "logits = torch.randn(2, 4, 10)\n",
    "# Simulate ground truth target tokens\n",
    "target = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "# Calculate perplexity\n",
    "perplexity = calculate_perplexity(logits, target)\n",
    "print(f'Perplexity: {perplexity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fe3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     62\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quick brown fox jumps over the lazy dog.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA journey of a thousand miles begins with a single step.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m ]\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerplexity scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculate_batch_perplexity(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 57\u001b[0m, in \u001b[0;36mcalculate_batch_perplexity\u001b[0;34m(input_texts)\u001b[0m\n\u001b[1;32m     54\u001b[0m     perplexities \u001b[38;5;241m=\u001b[39m perplexities\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Take mean of perplexities of each batch\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     mean_perplexity_score \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(perplexities)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexities\u001b[39m\u001b[38;5;124m\"\u001b[39m: perplexities, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_perplexity\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_perplexity_score}\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the model and tokenizer (e.g., GPT-2)\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Assign the EOS token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def calculate_batch_perplexity(input_texts):\n",
    "    \"\"\"\n",
    "    Calculate perplexity for a batch of input texts using a pretrained language model.\n",
    "\n",
    "    Args:\n",
    "    - input_texts (List[str]): A list of input texts to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - List[float]: A list of perplexity scores, one for each input text.\n",
    "    \"\"\"\n",
    "    # Tokenize the batch of texts with padding for uniform length\n",
    "    inputs = tokenizer(\n",
    "        input_texts, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Pass the input batch through the model to get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Shift the logits and input_ids to align targets correctly\n",
    "    # Logits dimensions are: (batch_size, seq_length, vocab_size) \n",
    "    shift_logits = logits[:, :-1, :]  # Ignore the last token's logits\n",
    "    shift_labels = input_ids[:, 1:]   # Skip the first token in the labels\n",
    "\n",
    "    # Compute log probabilities\n",
    "    log_probs = torch.nn.functional.log_softmax(shift_logits, dim=-1)\n",
    "\n",
    "    # Gather the log probabilities for the correct tokens\n",
    "    target_log_probs = log_probs.gather(dim=-1, index=shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Mask out positions corresponding to padding tokens\n",
    "    target_log_probs = target_log_probs * attention_mask[:, 1:].to(log_probs.dtype)\n",
    "\n",
    "    # Compute the mean negative log-likelihood for each sequence\n",
    "    negative_log_likelihood = -target_log_probs.sum(dim=-1) / attention_mask[:, 1:].sum(dim=-1)\n",
    "\n",
    "    # Compute perplexity for each sequence\n",
    "    perplexities = torch.exp(negative_log_likelihood)\n",
    "    perplexities = perplexities.tolist()\n",
    "    \n",
    "    # Take mean of perplexities of each batch\n",
    "    mean_perplexity_score = torch.mean(perplexities)\n",
    "\n",
    "    return {\"perplexities\": perplexities, \"mean_perplexity\": mean_perplexity_score}\n",
    "\n",
    "# Example usage\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\"\n",
    "]\n",
    "print(f\"Perplexity scores: {calculate_batch_perplexity(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05563e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
