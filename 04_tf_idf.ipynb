{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b04a9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and', 'are', 'cat', 'cats', 'dog', 'dogs', 'friends', 'log', 'mat', 'on', 'sat', 'the']\n",
      "Document 1 TF-IDF:\n",
      "[0, 0, 0.06757751801802739, 0, 0, 0, 0, 0, 0.06757751801802739, 0.0, 0.0, 0.0]\n",
      "Document 2 TF-IDF:\n",
      "[0, 0, 0, 0, 0.06757751801802739, 0, 0, 0.06757751801802739, 0, 0.0, 0.0, 0.0]\n",
      "Document 3 TF-IDF:\n",
      "[0.08109302162163289, 0.08109302162163289, 0, 0.08109302162163289, 0, 0.08109302162163289, 0.08109302162163289, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_tf(doc):\n",
    "    tf = defaultdict(float)\n",
    "    for word in doc:\n",
    "        tf[word] += 1\n",
    "    total_words = len(doc)\n",
    "    for word in tf:\n",
    "        tf[word] /= total_words\n",
    "    return tf\n",
    "\n",
    "def compute_idf(corpus, vocab):\n",
    "    N = len(corpus)\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        containing_docs = sum(1 for doc in corpus if word in doc)\n",
    "        idf[word] = math.log(N / (1 + containing_docs))  # Smoothed IDF\n",
    "    return idf\n",
    "\n",
    "def compute_tfidf(tf, idf, vocab):\n",
    "    tfidf = [0] * len(vocab)\n",
    "    word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "    for word, value in tf.items():\n",
    "        word_idx = word_to_index[word]\n",
    "        tfidf[word_idx] = value * idf[word]\n",
    "    return tfidf\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"cats and dogs are friends\"\n",
    "]\n",
    "\n",
    "# Tokenize the corpus\n",
    "tokenized_docs = [doc.lower().split() for doc in corpus]\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = sorted(set(word for doc in tokenized_docs for word in doc))\n",
    "\n",
    "# Compute TF for each document\n",
    "tf_list = [compute_tf(doc) for doc in tokenized_docs]\n",
    "\n",
    "# Compute IDF for the whole corpus\n",
    "idf = compute_idf(tokenized_docs, vocab)\n",
    "\n",
    "# Compute TF-IDF vectors for each document\n",
    "tfidf_vectors = [compute_tfidf(tf, idf, vocab) for tf in tf_list]\n",
    "\n",
    "# Output results\n",
    "print(\"Vocabulary:\", vocab)\n",
    "for i, vec in enumerate(tfidf_vectors):\n",
    "    print(f\"Document {i+1} TF-IDF:\")\n",
    "    print(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29a40ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'friends' 'log' 'mat' 'on' 'sat'\n",
      " 'the']\n",
      "TF-IDF Vectors:\n",
      "[[0.         0.         0.42755362 0.         0.         0.\n",
      "  0.         0.         0.42755362 0.32516555 0.32516555 0.6503311 ]\n",
      " [0.         0.         0.         0.         0.42755362 0.\n",
      "  0.         0.42755362 0.         0.32516555 0.32516555 0.6503311 ]\n",
      " [0.4472136  0.4472136  0.         0.4472136  0.         0.4472136\n",
      "  0.4472136  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"cats and dogs are friends\"\n",
    "]\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the corpus to get the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert to dense array\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print results\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"TF-IDF Vectors:\")\n",
    "print(tfidf_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c1693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
